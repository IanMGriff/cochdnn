data:
  root: '/mnt/ceph/users/jfeather/data/training_datasets_audio/JSIN_all_v3/subsets/'

audio_rep:                                  # Attributes of audio feature
  name: 'cochleagram_1'
  on_gpu: True

audio_transforms:
  low_snr: -10
  high_snr: 10
  dbspl: 60

val_metric:
    word_task: 'val_signal/word_int_acc'

hparas:                                   # Experiment hyper-parameters
  epochs: 10                              # Each "epoch" is 25 passes through the speech dataset
  batch_size: 768
  optimizer: "LARS"
  lr: 0.2                                # initial LR 
  num_warmup_steps_or_ratio: 0.1
  lambda_ssl: 1
  valid_step: 5000
  ssl_task: 'word'                            # either 'word', 'audioset', 'dual'
  ssl_loss_str: 'mmcr'
  ssl_loss: 'MMCR'
  ssl_loss_kwargs:
    lmbda: 0.0

model:                                    # Model architecture
  arch_name: "SSLAudioModel"
  arch_kwargs:
    projector_dims: [512, 512]
    proj_out_dim: 2048
    n_classes: 794
    supervised: False
    