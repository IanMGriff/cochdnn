{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import lightning as L\n",
    "\n",
    "import lightning_scripts.lightning as lightning \n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(lightning)\n",
    "LitAudioSSL = lightning.LitAudioSSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## init config. Will be yaml eventually, but start as dict \n",
    "\n",
    "config = {}\n",
    "config['audio_rep'] = dict(name='cochleagram_1', on_gpu=True)\n",
    "config['audio_transforms'] = { 'low_snr':-10, 'high_snr':10, 'dbspl':60 }\n",
    "config['data'] = {'root':\"/mnt/ceph/users/jfeather/data/training_datasets_audio/JSIN_all_v3/subsets/\"}\n",
    "config['model'] = {\n",
    "    'arch_name':'SSLAudioModel',\n",
    "    'arch_kwargs':dict(projector_dims=[512, 512], proj_out_dim=2048, n_classes=794, supervised=False)\n",
    "    }\n",
    "\n",
    "config['hparas'] = {\n",
    "    'batch_size': 32,\n",
    "    'lambda_mmcr': 0.5,\n",
    "    'optimizer': 'AdamW',\n",
    "    'lr': 3e-4,\n",
    "}\n",
    "config['num_workers'] = 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio_rep': {'name': 'cochleagram_1', 'on_gpu': True},\n",
       " 'audio_transforms': {'low_snr': -10, 'high_snr': 10, 'dbspl': 60},\n",
       " 'data': {'root': '/mnt/ceph/users/jfeather/data/training_datasets_audio/JSIN_all_v3/subsets/'},\n",
       " 'model': {'arch_name': 'SSLAudioModel',\n",
       "  'arch_kwargs': {'projector_dims': [512, 512],\n",
       "   'proj_out_dim': 2048,\n",
       "   'n_classes': 794,\n",
       "   'supervised': False}},\n",
       " 'hparas': {'batch_size': 32,\n",
       "  'lambda_mmcr': 0.5,\n",
       "  'optimizer': 'AdamW',\n",
       "  'lr': 0.0003},\n",
       " 'num_workers': 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitAudioSSL(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/igriffith/ceph/conda_envs/cochdnn_ssl_pl/lib/python3.12/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /mnt/home/igriffith/ceph/conda_envs/cochdnn_ssl_pl/l ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(limit_train_batches=5,\n",
    "                    limit_val_batches=2,\n",
    "                     max_epochs=5,\n",
    "                    #  reload_dataloaders_every_n_epochs=-1,\n",
    "                     devices=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/igriffith/ceph/conda_envs/cochdnn_ssl_pl/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /mnt/ceph/users/igriffith/projects/cochdnn/lightning_logs/version_3760973/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type                       | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | transforms | AudioCompose               | 0      | train\n",
      "1 | audio_rep  | AudioToAudioRepresentation | 0      | train\n",
      "2 | model      | ModelWithFrontEnd          | 26.4 M | train\n",
      "3 | mmcr_loss  | MMCR_Loss                  | 0      | train\n",
      "4 | class_loss | CrossEntropyLoss           | 0      | train\n",
      "------------------------------------------------------------------\n",
      "26.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "26.4 M    Total params\n",
      "105.762   Total estimated model params size (MB)\n",
      "170       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4179524f0148f6b2ad25de9936b4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/igriffith/ceph/conda_envs/cochdnn_ssl_pl/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b68ae1b7363412d8faeefdc9da282bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4bcabc9d2140a483e8bbba75a2161f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated rotation: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb112b46e5b46478503edd0eb0b4ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated rotation: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16042fb5d10242abad17902cb4762f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated rotation: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cochdnn_ssl_pl",
   "language": "python",
   "name": "cochdnn_ssl_pl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
