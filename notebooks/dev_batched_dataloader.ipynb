{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "\n",
    "from robustness.audio_functions.jsinV3DataLoader_precombined import *\n",
    "from robustness.audio_functions.audio_transforms import *\n",
    "\n",
    "import lightning_scripts.jsinV3DataLoader_precombined_batched as batched_jsin \n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_path = \"/mnt/ceph/users/jfeather/data/training_datasets_audio/JSIN_all_v3/subsets/valid_RQTTZB4C3TJJVLJUWDV72TYMC7S4MNHH/JSIN_all__run_000_RQTTZB4C3TJJVLJUWDV72TYMC7S4MNHH.h5\"\n",
    "example_path_dir = \"/mnt/ceph/users/jfeather/data/training_datasets_audio/JSIN_all_v3/subsets\"\n",
    "transform = AudioCompose(\n",
    "    [\n",
    "        AudioToTensor(),\n",
    "        CombineWithRandomDBSNR()\n",
    "    ]\n",
    ")\n",
    "example_dset = H5Dataset(example_path, transform=transform, target_keys=['signal/word_int'])\n",
    "#example_dset_paired = H5DatasetPaired(example_path, transform=transform, target_keys=['signal/word_int'])\n",
    "example_dset_all_sig = jsinV3_precombined_all_signals(example_path_dir, transform=transform, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run timing test for iteration with vs without transforms in dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "loader = torch.utils.data.DataLoader(example_dset_all_sig, batch_size=16, num_workers=0, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 s ± 26.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "for ix, _ in enumerate(loader):\n",
    "    if ix == 100:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run timing test for iteration without transforms in dataset \n",
    "\n",
    "example_dset_all_sig_raw = jsinV3_precombined_all_signals(example_path_dir, transform=None, train=True)\n",
    "raw_loader = torch.utils.data.DataLoader(example_dset_all_sig_raw, batch_size=16, num_workers=0, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.35 s ± 27.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "for ix, _ in enumerate(collated_loader):\n",
    "    if ix == 100:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(batched_jsin)\n",
    "batched_jsinV3_precombined_all_signals = batched_jsin.jsinV3_precombined_all_signals(example_path_dir, transform=transform, train=True, batch_size=16)\n",
    "batched_loader = torch.utils.data.DataLoader(batched_jsinV3_precombined_all_signals, batch_size=1, num_workers=0, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586 ms ± 5.32 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "for ix, _ in enumerate(batched_loader):\n",
    "    if ix == 100:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test if faster using transforms in collate function rather than dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch = batch[0] # unbox wrapper\n",
    "    signals = []\n",
    "    labels = batch[-1] # labels already collated \n",
    "    if isinstance(labels, dict):\n",
    "        for task_key, task_labels in labels.items():\n",
    "            labels[task_key] = torch.from_numpy(task_labels)\n",
    "    else:\n",
    "        labels = torch.from_numpy(labels) \n",
    "    # only need to convert fg and bg into signal, labels will be fine as-is\n",
    "    for (fg, bg) in  zip(*batch[:2]):\n",
    "        signal, _ = transform(fg, bg)\n",
    "        signals.append(signal)\n",
    "    signals = torch.vstack(signals)\n",
    "    return signals, labels \n",
    "\n",
    "\n",
    "importlib.reload(batched_jsin)\n",
    "batched_jsinV3_precombined_all_signals = batched_jsin.jsinV3_precombined_all_signals(example_path_dir, transform=None, train=True, batch_size=16)\n",
    "collated_loader = torch.utils.data.DataLoader(batched_jsinV3_precombined_all_signals, batch_size=1, num_workers=2, shuffle=False, pin_memory=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batched_jsinV3_precombined_all_signals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.57629395,  0.27570432, -0.17647317, ..., -1.2251    ,\n",
      "       -1.9700506 , -1.8175945 ], dtype=float32), array([0.8073209 , 2.523126  , 0.37178677, ..., 0.12427753, 0.20780419,\n",
      "       0.40587074], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "for row in zip(*batch[:2]):\n",
    "    print(row)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start ix: 0 \n",
      "start ix: 16 \n",
      "start ix: 32 \n",
      "start ix: 48 \n",
      "start ix: 80 start ix: 64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "for ix, _ in enumerate(batched_loader):\n",
    "    if ix == 7:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(collated_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Iter test to make sure different workers are grabbing distinct batches \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start ix: 0 on pid 596819start ix: 16 on pid 596820\n",
      "\n",
      "start ix: 32 on pid 596819\n",
      "start ix: 48 on pid 596820\n",
      "start ix: 64 on pid 596819\n",
      "start ix: 96 on pid 596819start ix: 80 on pid 596820\n",
      "\n",
      "start ix: 128 on pid 596819\n"
     ]
    }
   ],
   "source": [
    "for ix, batch in enumerate(collated_loader):\n",
    "    if ix == 6:\n",
    "        break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cochdnn_ssl_pl",
   "language": "python",
   "name": "cochdnn_ssl_pl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
